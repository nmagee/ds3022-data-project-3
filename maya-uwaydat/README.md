# how sensational!

## using sentiment analysis to investigate correlations between development of communications technology, and the sensationalisation of news 
maya uwaydat
[link to code repo](https://github.com/mayooueidat-uva/dp3-project3-code-repo)

#### about 
+ in ninth grade civics class, i learned about how the advent of 24-hour television caused greater political polarisation in the united states and how social media echo chambers only exacerbated the disunity felt between people on opposite sides of the political spectrum. if news is increasingly polarised, and if [the development of communications technology](https://education.cfr.org/media/history-communications) have only aided in polarisation, then maybe even the most reliable news must stir the worst of people's emotions in order to compete for their attention and win their hearts and minds.
+ to investigate the relationship between technological evolution and sensationalisation, i conducted sentiment analysis on both headlines and snippets of news articles, using the new york times as a case study. note: sensationalisation is not polarisation; polarisation is more about planting seeds of division while sensationalisation is more about making something as eye-catching and/or shocking as possible.
+ sensationalisation becomes a reflection of how much the news actually serves its role of constructively informing the public. in high school, i did quite the bit of research about the symbiotic relationship between terrorism and journalism; terrorist attacks don't cause too many deaths, [but are overrepresented in news](https://ourworldindata.org/does-the-news-reflect-what-we-die-from), because news is a for-profit enterprise that needs to keep your attention to stay afloat and terrorism is morbidly entertaining to people. when news outlets use stories to shock instead of neutrally inform, it provides a distorted picture of reality. 

#### tools in the pipeline 
+ prefect: allows for easy orchestration of tasks. the data had to be pulled from the api, transformed, and shoved through a sentiment analysis algorithm; furthermore, for the sake of more robust analysis, i had to create a line plot. prefect allows me to do this all with one file, all in one go. 
+ pandas dataframes: for easy storage of data from the api before transformation in a way that the api could understand.
+ duckdb/sql: i needed a more permanent place to store data that i fetched from api calls so i wouldn't have to re-fetch everything any time i had to go back and re-edit my code. duckdb provided this structure. 
+ vader: vader is a sentiment analysis tool specialised for social media posts, but it has been used for news articles as well. further insight: [analysis of vader vs. textblob](https://jds-online.org/journal/JDS/article/1441/info)

#### data
+ the data was fetched from the nyt developer api. the 'raw data' included in this project include the date the article was published, the article's headline, and the article's snippet (the small piece of text right under the header giving a brief description of what the full article is about). 
+ ALL new york times articles from 1924 to 2024 released in january or june were included in the study. 1928 was the year of the first television broadcast ([source](https://education.cfr.org/media/history-communications)), so including the last century's worth of data made sense for interpretability's sake. 
+ the article headline and article snippet were fed into a vader sentiment analyser to give us a) the vader sentiment score for the headline of each article, and b) the vader sentiment score for the snippet of each article. 
+ the final data table included: year and month (as a timestamp), average sentiment score for headlines for each given time period, average sentiment scores for snippets for each given time period. 

#### limitations
+ this study uses *only* the new york times and its api. at first, i was considering looking at the top 3 newspapers (nyt, wsj and wp); however, the washington post does not have an api. the new york times was chosen for easy use of its api, its long history, and the fact that it is the [number one most-subscribed newspaper](https://en.wikipedia.org/wiki/List_of_newspapers_in_the_United_States) in the united states. a more comprehensive analysis would have taken into account *multiple* different newspaper outlets, television, podcasts, and other media. a project of that scale is something for future me, maybe.
+ i also did not use the full articles; the headlines and the snippets are used as a proxy for "the sensationalisation of news." while they *are* indeed what is competing most for viewers' attention, the actual contents of the news might still use fairly neutral language.
+ 'sensationalisation'  is subjective; a sentiment analysis is the closest i'd get to quantifying it. 

#### challenges with this project 
+ limitations of the nyt api itself. i'm only allowed to make 5 api calls a minute and 500 calls a day. that greatly restricted the volume of my data; additionally, it forced me to be frugal with how many times i test-ran the pipeline.
+ because i'm gathering data from over the course of a century, the pipeline takes *awhile* to run. like, give it a good 40-50 minutes. if there was some error in my code that prevented my data from being stored in a permanent database, i could lose a lot of precious time because i'd have to fetch it again. 

#### running the pipeline
running this pipeline is quite simple; the entire pipeline is condensed into one prefect flow. all one must do is launch a virtual environment, ensure that all the required packages are installed, and run the python file. **NOTE:** you need a key from the new york times developer api, which you will pass into your virtual environment. you can get one for free signing up at https://developer.nytimes.com/ and upon creating an app (instructions for creating an app included on the website). 

#### findings and results 
![nyt_sentiment_graph](https://raw.githubusercontent.com/mayooueidat-uva/ds3022-data-project-3/refs/heads/main/nyt_sentiment_plot.png)
(note: a value closer to 1 implies more positive sentiment; a value closer to 0 means a more neutral sentiment; a value closer to -1 is more negative) the evolution of technology corresponds with stronger "sentiments" in news, but not in the manner i expected. throughout most of the 20th century, sentiments in news headlines and snippets orbit around zero, even during pivotal events such as the united state's participation in wwii (early 1940s) and the civil rights movement (1960s). however, after google's launch, one sees a strong positive trend in snippet sentiment (though title sentiment stays rather level); and interestingly, both title and snippet sentiments take a sharp downard turn shortly after the launch of the iphone. however, i hypothesise that the catalyst for this was the 2008 financial crisis, though communications technologies could have played a role in maintaining the trend given how social media *now* seeks to maximise engagement ([and maintaining attention requires being rage-inducing](https://www.npr.org/transcripts/1122786134)). my expectation was that the internet's beginnings would foster a consistently stronger *negative* sentiment, not that there would be peaks and valleys in the emotions conveyed by potentially sensationalised headlines. maybe the new's attempts to maintain a hold on people's media-bombarded minds are not always gossipy or sensational or harmful; somehow, perhaps, they needed to speak to people's morale. 

## all relevant sources (except for the new york times api itself) are hyperlinked in this readme. 
